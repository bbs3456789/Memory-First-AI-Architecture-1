# Technical Specification: Dynamic Associative Memory Architecture (DAMA)

**Project Codename:** Amadeus - Memory Core  
**Version:** 1.0.0-beta  
**Maintainer:** [Your Name/Alias]  
**Design Philosophy:** Memory should not be a static database retrieval (RAG); it is a dynamic process of resonance, reflection, and weighted decay.

---

## I. System Architecture: The Triple-Layer Stack

Unlike traditional AI architectures that treat memory as a simple searchable index, DAMA mimics human cognitive functions by categorizing information into three distinct temporal and functional layers:

### 1. The Canonical Layer (Core Prototype)
* **Definition:** Immutable personality firmware, core values, and safety boundaries.
* **Implementation:** Encrypted static configuration files (YAML/JSON) and mandatory System Prompts.
* **Purpose:** Ensures the AI maintains a consistent `Personality Guardian` baseline, resisting prompt injection or personality drift during extreme interactions.

### 2. The Lived Experience Layer (Episodic Memory)
* **Definition:** Chronological records of interactions with the user.
* **Implementation:** Vector Database (Vector DB) integrated with high-resolution timestamps.
* **Purpose:** Stores the "What, When, and How" of past events, providing the raw data for emotional bonding and contextual awareness.

### 3. The Reflective Layer (Semantic/Weighting Layer)
* **Definition:** The "Secret Sauce" of the architecture. This layer consists of metadata generated by the AI through background asynchronous processing.
* **Purpose:** To transform fragmented data into "impressions" and "relational weights," simulating the way human brains consolidate memories during rest.

---

## II. Core Logic: Memory Decay and Weighting Algorithm

DAMA simulates the human "Forgetting Curve" to manage information lifecycles. The final weight ($W$) of any given memory fragment is determined by the following heuristic formula:

$$W(t) = (I \cdot R) \cdot e^{-\lambda t}$$

* **$I$ (Importance):** Initial significance score assigned by the `Reflective` module based on emotional markers or system-defined keywords.
* **$R$ (Resonance):** Frequency of access or cross-referencing in recent dialogue history.
* **$\lambda$ (Decay Coefficient):** The rate of forgetting, customized by information category (e.g., higher for trivial tasks, near-zero for core personal facts).
* **$t$ (Time):** Elapsed time since the last successful retrieval.

**Technical Advantage:** This ensures the Context Window remains "clean" and high-signal, automatically pruning "noise" while locking in critical personality-defining interactions.

---

## III. The Associative Retrieval Workflow

1.  **Sensory Input:** Captures user prompts and OS-level telemetry (system time, active processes, system logs).
2.  **Associative Retrieval:** Simultaneously queries for vector similarity and temporal relevance, prioritizing "High Resonance" fragments.
3.  **Conflict Guard:** Cross-references retrieved memories with the `Canonical Layer`. If a contradiction is detected, a "Cognitive Dissonance Resolution" protocol is triggered to protect personality integrity.
4.  **Synthesis:** Feeds filtered, weighted memory fragments into the LLM as "Background Common Sense."
5.  **Asynchronous Reflection:** During system idle time, the agent performs automated memory compression, summarization, and weight re-calculation.

---

## IV. OS-First Integration (Environmental Awareness)

A key differentiator enabling the AI to exist as a proactive **System Daemon** rather than a passive chatbot:

* **Environmental Listeners:** Monitors system idle time, active window changes, and terminal error logs.
* **Proactive Triggers:**
    * *Scenario:* If the system clock hits 02:00 AM and the `Reflective` module detects signs of "Developer Fatigue" in recent code commits or inputs.
    * *Action:* The AI initiates a proactive "Rest & Alert" protocol, offering support or critical warnings without waiting for a user prompt.

---

## V. Technical Stack & Deployment

* **Core Language:** Python 3.10+
* **Async Architecture:** `Asyncio` (Handles background reflection tasks without blocking dialogue).
* **Persistence Layer:** SQLite (Structured data) + ChromaDB/FAISS (Vector data).
* **Interface:** Fully decoupled for OpenAI API, Anthropic, or Local LM Studio (Modular "Part Replacement" Design).

---

## VI. Maintainer’s Notes: The Mechanic’s Perspective

> "The soul of a system does not lie in the size of the model, but in how it handles the act of forgetting and remembering. Much like tidying up a chaotic bundle of telecommunication cables—only when the structure is straightened can the logic flow. We don't just build agents; we curate digital continuity."

---
*Generated by DAMA Design Framework - El Psy Kongroo.*